{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Read Training data\n",
    "metadata_df = pd.read_csv(\"Results/meta_plus_ratings.csv\")\n",
    "# Read Test data\n",
    "#metadata_test_df = pd.read_csv(\"data/Test_Set/metadata_test_plus_ratings.csv\")\n",
    "\n",
    "# Convert the runtime into int\n",
    "metadata_df[\"runtime\"] = metadata_df[\"runtime\"].apply(lambda x: x.split(\" min\")[0])\n",
    "metadata_df[\"runtime\"] = metadata_df[\"runtime\"].astype(float)\n",
    "\n",
    "# Features\n",
    "metadata_x = metadata_df.drop(\"goodforairplane\", axis=1)\n",
    "# Target\n",
    "metadata_Y = metadata_df[\"goodforairplane\"]\n",
    "\n",
    "# Same for test set\n",
    "# Features\n",
    "#metadata_test_x = metadata_test_df.drop(\"goodforairplane\", axis=1)\n",
    "# Target\n",
    "#metadata_test_Y = metadata_test_df[\"goodforairplane\"]\n",
    "\n",
    "# Map the age rating to the corresponding integer\n",
    "age_mapping = {\"PG-13\": 13., \"R\": 17., \"TV-MA\": 18., \"G\": 1., \"PG\": 10., \"NOT RATED\": 0., \"APPROVED\": 0., np.nan: 0.}\n",
    "metadata_x[\"rated\"] = metadata_x[\"rated\"].map(age_mapping)\n",
    "\n",
    "# Impute the missing values of training data\n",
    "values = metadata_x.iloc[:,list(range(3,7))].values\n",
    "imputer = IterativeImputer(random_state=1)\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "colnames= metadata_x.columns[3:7]\n",
    "metadata_x[colnames] = transformed_values\n",
    "# Impute the missing values of test data\n",
    "#values = metadata_test_x.iloc[:,list(range(3,7))].values\n",
    "#imputer = IterativeImputer(random_state=1)\n",
    "#transformed_values = imputer.fit_transform(values)\n",
    "#colnames= metadata_test_x.columns[3:7]\n",
    "#metadata_test_x[colnames] = transformed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(50)\n",
    "\n",
    "def LVW(meta_x, meta_Y, K, classifier):\n",
    "    err = 0\n",
    "    k = 0\n",
    "    C = 100\n",
    "    # Best features\n",
    "    S = np.array([])\n",
    "    # Create list of features\n",
    "    while k < K:\n",
    "        # Create a list of available features\n",
    "        features_ind = np.array(list(range(0, len(meta_x.columns))))\n",
    "        num_features = len(features_ind)\n",
    "        # Generate how many features should be selected\n",
    "        C1 = np.random.randint(1,num_features+1)\n",
    "        # Randomly pick num_selected_features as subset\n",
    "        S1_ind = np.random.choice(features_ind, size=C1, replace = False)\n",
    "        # Sort it, because it looks nicer...\n",
    "        S1_ind = np.sort(S1_ind)\n",
    "        # Train the classifier\n",
    "        classifier.fit(meta_x.iloc[:,S1_ind], meta_Y)\n",
    "        # Predict the results\n",
    "        pred = classifier.predict(meta_x.iloc[:,S1_ind])\n",
    "        # Comptue f1 measure (since in the paper it is stated that they tune it based on the f1 score)\n",
    "        f1 = f1_score(meta_Y, pred)\n",
    "        \n",
    "        if (f1 > err or (f1 == err and C1 < C)):\n",
    "            k = 0\n",
    "            S = S1_ind\n",
    "            err = f1\n",
    "            C = C1\n",
    "        else:\n",
    "            k = k+1\n",
    "    # Test on testset\n",
    "    classifier.fit(meta_x.iloc[:,S], meta_Y)\n",
    "    \n",
    "    # Get column names\n",
    "    columns = meta_x.iloc[:,S].columns\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: KNeighborsClassifier, Modality: metadata, Precision: 0.586, Recall: 0.647, F1: 0.592\n",
      "Classifier: NearestCentroid, Modality: metadata, Precision: 0.478, Recall: 0.557, F1: 0.502\n",
      "Classifier: DecisionTreeClassifier, Modality: metadata, Precision: 0.524, Recall: 0.617, F1: 0.549\n",
      "Classifier: LogisticRegression, Modality: metadata, Precision: 0.493, Recall: 0.560, F1: 0.520\n",
      "Classifier: SVC, Modality: metadata, Precision: 0.519, Recall: 0.720, F1: 0.599\n",
      "Classifier: BaggingClassifier, Modality: metadata, Precision: 0.487, Recall: 0.467, F1: 0.456\n",
      "Classifier: RandomForestClassifier, Modality: metadata, Precision: 0.493, Recall: 0.450, F1: 0.464\n",
      "Classifier: AdaBoostClassifier, Modality: metadata, Precision: 0.480, Recall: 0.600, F1: 0.523\n",
      "Classifier: GradientBoostingClassifier, Modality: metadata, Precision: 0.453, Recall: 0.460, F1: 0.453\n",
      "Classifier: GaussianNB, Modality: metadata, Precision: 0.515, Recall: 0.580, F1: 0.533\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(50)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define Scoring methods\n",
    "scoring = {'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "classifiers = [KNeighborsClassifier(), NearestCentroid(), \n",
    "               DecisionTreeClassifier(), LogisticRegression(),\n",
    "               SVC(), BaggingClassifier(), RandomForestClassifier(),\n",
    "               AdaBoostClassifier(), GradientBoostingClassifier(), GaussianNB()]\n",
    "\n",
    "for classi in classifiers:\n",
    "    # Perform LVW (not for random forest)\n",
    "    if isinstance(classi, RandomForestClassifier):\n",
    "        ind = LVW(metadata_x, metadata_Y, 10, classi)\n",
    "        scores = cross_validate(classi, X=metadata_x, y=metadata_Y, cv=10,scoring=scoring)\n",
    "        f_1 = np.mean(scores[\"test_f1_score\"])\n",
    "        precision = np.mean(scores[\"test_precision\"])\n",
    "        recall = np.mean(scores[\"test_recall\"])\n",
    "    else:\n",
    "        ind = LVW(metadata_x, metadata_Y, 10, classi)\n",
    "        scores = cross_validate(classi, X=metadata_x[ind], y=metadata_Y, cv=10,scoring=scoring)\n",
    "        f_1 = np.mean(scores[\"test_f1_score\"])\n",
    "        precision = np.mean(scores[\"test_precision\"])\n",
    "        recall = np.mean(scores[\"test_recall\"])\n",
    "    print(\"Classifier: %s, Modality: metadata, Precision: %.3f, Recall: %.3f, F1: %.3f\" % (classi.__class__.__name__, precision, recall, f_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
