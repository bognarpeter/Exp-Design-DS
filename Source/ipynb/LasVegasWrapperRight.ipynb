{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "textual_df = pd.read_csv(\"../../Results/textual.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "metadata_x = textual_df.drop(\"goodforairplane\", axis=1)\n",
    "# Target\n",
    "metadata_Y = textual_df[\"goodforairplane\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(50)\n",
    "\n",
    "def LVW(meta_x, meta_Y, K, classifier):\n",
    "    err = 0\n",
    "    k = 0\n",
    "    C = 100\n",
    "    # Best features\n",
    "    S = np.array([])\n",
    "    # Create list of features\n",
    "    while k < K:\n",
    "        # Create a list of available features\n",
    "        features_ind = np.array(list(range(0, len(meta_x.columns))))\n",
    "        num_features = len(features_ind)\n",
    "        # Generate how many features should be selected\n",
    "        C1 = np.random.randint(1,num_features+1)\n",
    "        # Randomly pick num_selected_features as subset\n",
    "        S1_ind = np.random.choice(features_ind, size=C1, replace = False)\n",
    "        # Sort it, because it looks nicer...\n",
    "        S1_ind = np.sort(S1_ind)\n",
    "        # Train the classifier\n",
    "        classifier.fit(meta_x.iloc[:,S1_ind], meta_Y)\n",
    "        # Predict the results\n",
    "        pred = classifier.predict(meta_x.iloc[:,S1_ind])\n",
    "        # Comptue f1 measure (since in the paper it is stated that they tune it based on the f1 score)\n",
    "        f1 = f1_score(meta_Y, pred)\n",
    "        \n",
    "        if (f1 > err or (f1 == err and C1 < C)):\n",
    "            k = 0\n",
    "            S = S1_ind\n",
    "            err = f1\n",
    "            C = C1\n",
    "        else:\n",
    "            k = k+1\n",
    "    # Test on testset\n",
    "    classifier.fit(meta_x.iloc[:,S], meta_Y)\n",
    "    #test_pred = classifier.predict()\n",
    "    \n",
    "    # Get column names\n",
    "    columns = meta_x.iloc[:,S].columns\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: KNeighborsClassifier, Modality: metadata, Precision: 0.604, Recall: 0.615, F1: 0.610\n",
      "Classifier: SVC, Modality: metadata, Precision: 0.547, Recall: 1.000, F1: 0.707\n",
      "Classifier: GaussianNB, Modality: metadata, Precision: 0.583, Recall: 0.404, F1: 0.477\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(50)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define Scoring methods\n",
    "scoring = {'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "classifiers = [KNeighborsClassifier(),\n",
    "               SVC(), GaussianNB()]\n",
    "\n",
    "for classi in classifiers:\n",
    "    # Perform LVW (not for random forest)\n",
    "    if isinstance(classi, RandomForestClassifier):\n",
    "        #ind = LVW(metadata_x, metadata_Y, 10, classi)\n",
    "        scores = cross_validate(classi, X=metadata_x, y=metadata_Y, cv=10,scoring=scoring)\n",
    "        f_1 = np.mean(scores[\"test_f1_score\"])\n",
    "        precision = np.mean(scores[\"test_precision\"])\n",
    "        recall = np.mean(scores[\"test_recall\"])\n",
    "    else:\n",
    "        ind = LVW(metadata_x, metadata_Y, 10, classi)\n",
    "        #scores = cross_validate(classi, X=metadata_x[ind], y=metadata_Y, cv=10,scoring=scoring)\n",
    "        scores = perform_cross_validation(metadata_x[ind], metadata_Y, classi)\n",
    "        #f_1 = np.mean(scores[\"test_f1_score\"])\n",
    "        #precision = np.mean(scores[\"test_precision\"])\n",
    "        #recall = np.mean(scores[\"test_recall\"])\n",
    "        precision = scores[0]\n",
    "        recall = scores[1]\n",
    "        f_1 = scores[2]\n",
    "    print(\"Classifier: %s, Modality: metadata, Precision: %.3f, Recall: %.3f, F1: %.3f\" % (classi.__class__.__name__, precision, recall, f_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: KNeighborsClassifier, Modality: metadata, Precision: 0.604, Recall: 0.615, F1: 0.610\n",
      "Classifier: SVC, Modality: metadata, Precision: 0.547, Recall: 1.000, F1: 0.707\n",
      "Classifier: GaussianNB, Modality: metadata, Precision: 0.583, Recall: 0.404, F1: 0.477\n",
      "Classifier: RandomForestClassifier, Modality: metadata, Precision: 0.442, Recall: 0.442, F1: 0.442\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(50)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define Scoring methods\n",
    "scoring = {'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "classifiers = [KNeighborsClassifier(),\n",
    "               SVC(), GaussianNB(), RandomForestClassifier()]\n",
    "\n",
    "for classi in classifiers:\n",
    "    # Perform LVW (not for random forest)\n",
    "    if isinstance(classi, RandomForestClassifier):\n",
    "        #ind = LVW(metadata_x, metadata_Y, 10, classi)\n",
    "        #scores = cross_validate(classi, X=metadata_x[ind], y=metadata_Y, cv=10,scoring=scoring)\n",
    "        scores = perform_cross_validation(metadata_x, metadata_Y, classi)\n",
    "        #f_1 = np.mean(scores[\"test_f1_score\"])\n",
    "        #precision = np.mean(scores[\"test_precision\"])\n",
    "        #recall = np.mean(scores[\"test_recall\"])\n",
    "        precision = scores[0]\n",
    "        recall = scores[1]\n",
    "        f_1 = scores[2]\n",
    "    else:\n",
    "        ind = LVW(metadata_x, metadata_Y, 10, classi)\n",
    "        #scores = cross_validate(classi, X=metadata_x[ind], y=metadata_Y, cv=10,scoring=scoring)\n",
    "        scores = perform_cross_validation(metadata_x[ind], metadata_Y, classi)\n",
    "        #f_1 = np.mean(scores[\"test_f1_score\"])\n",
    "        #precision = np.mean(scores[\"test_precision\"])\n",
    "        #recall = np.mean(scores[\"test_recall\"])\n",
    "        precision = scores[0]\n",
    "        recall = scores[1]\n",
    "        f_1 = scores[2]\n",
    "    print(\"Classifier: %s, Modality: metadata, Precision: %.3f, Recall: %.3f, F1: %.3f\" % (classi.__class__.__name__, precision, recall, f_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def perform_cross_validation(X, y, classi):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        X_train = X.loc[train_idx]\n",
    "        X_test = X.loc[test_idx]\n",
    "        y_train = y.loc[train_idx]\n",
    "        y_test = y.loc[test_idx]\n",
    "        # Perform Las Vegas Wrapper\n",
    "        ind = LVW(X_train, y_train, 10, classi)\n",
    "        \n",
    "        classi.fit(X_train[ind], y_train)\n",
    "        # Predict\n",
    "        fold_predictions = classi.predict(X_test[ind])\n",
    "        ground_truth.extend(y_test)\n",
    "        predictions.extend(fold_predictions)\n",
    "    \n",
    "    # Compute the metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    f1 = f1_score(ground_truth, predictions)\n",
    "    return precision, recall, f1\n",
    "\n",
    "#perform_cross_validation(metadata_x, metadata_Y )\n",
    "#kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#for train_idx, test_idx in kf.split(metadata_x, metadata_Y):\n",
    "        #classi.fit(X[train_idx], y[train_idx])\n",
    "        #print(metadata_x[train_idx])\n",
    "        # Predict\n",
    "        #fold_predictions = classi.predict(X[test_idx])\n",
    "#        print(\"Hello\")\n",
    "#metadata_x.iloc[3, [1,2,3]]\n",
    "#metadata_x.loc[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
