{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sleeping_Beauty.xml', 'Foxcatcher.xml', 'The_Trip_to_Italy.xml', 'A_Little_Chaos.xml', 'Bad_News_Bears.xml', 'Run_Lola_Run.xml', 'Love_Actually.xml', '12_Years_a_Slave.xml', 'Kundo__Age_of_the_Rampant.xml', 'The_Best_of_Me.xml', 'A_Most_Wanted_Man.xml', 'The_Simpsons_Movie.xml', 'Homeland.xml', 'Bride_Flight.xml', 'Rise_of_the_Planet_of_the_Apes.xml', 'Banklady.xml', 'Silver_Linings_Playbook.xml', 'Godzilla.xml', 'Antz.xml', 'The_Hobbit__An_Unexpected_Journey.xml', 'The_Shawshank_Redemption.xml', 'Mr._Turner.xml', 'Hum_Aapke_Hain_Koun...!.xml', 'Legally_Blonde.xml', 'The_Inglorious_Bastards.xml', 'Soof.xml', 'Testament_of_Youth.xml', 'Dilwale_Dulhania_Le_Jayenge.xml', 'Prometheus.xml', 'Maps_to_the_Stars.xml', 'Bewakoofiyaan.xml', 'Big_Game.xml', 'Blow_Out.xml', 'Fast_Five.xml', 'Verliefd_op_Ibiza.xml', 'Leviathan.xml', 'The_English_Patient.xml', 'And_So_It_Goes.xml', 'Alice_in_Wonderland.xml', 'The_Great_Escape.xml', 'Smokey_and_the_Bandit.xml', 'Magic_in_the_Moonlight.xml', 'Edge_of_Tomorrow.xml', 'Cascadeur.xml', 'Lilting.xml', 'Begin_Again.xml', 'The_Big_Chill.xml', 'The_Silence_of_the_Lambs.xml', 'The_Green_Mile.xml', 'Star_Wars__Episode_IV_-_A_New_Hope.xml', 'Finding_Nemo.xml', 'Walk_the_Line.xml', 'The_Mummy.xml', 'Mommie_Dearest.xml', 'Harry_Potter_and_the_Deathly_Hallows__Part_2.xml', 'The_Incredibles.xml', 'The_Grand_Budapest_Hotel.xml', 'The_Wolf_of_Wall_Street.xml', 'Gunday.xml', 'The_Social_Network.xml', 'Beetlejuice.xml', 'Dolphin_Tale_2.xml', 'A_Simple_Life.xml', 'Titanic.xml', 'Humpty_Sharma_Ki_Dulhania.xml', 'The_Drop.xml', 'Pocahontas.xml', 'The_Croods.xml', 'Iron_Man_3.xml', 'Miss_Sixty.xml', 'Katalin_Varga.xml', 'Justin_Bieber__Never_Say_Never.xml', 'Yentl.xml', 'Warrior.xml', 'Dorsvloer_vol_confetti.xml', 'Iron_Man_2.xml', 'Maleficent.xml', 'Kurt_Cobain__Montage_of_Heck.xml', 'Aanmodderfakker.xml', 'Rab_Ne_Bana_Di_Jodi.xml', 'La_foresta_di_ghiaccio.xml', 'The_Talented_Mr._Ripley.xml', 'Loft.xml', 'Wet_Hot_American_Summer.xml', 'Happy_New_Year.xml', 'Karan_Arjun.xml', 'The_Girl_with_the_Dragon_Tattoo.xml', 'Limitless.xml', 'Lucy.xml', '2_States.xml', 'Mary_Kom.xml', 'Lost_Highway.xml', 'Fargo.xml', 'The_AristoCats.xml', 'Gooische_vrouwen.xml', 'Valkyrie.xml', 'The_Queen.xml', 'Thor__The_Dark_World.xml', 'The_Expendables_3.xml', 'Mommy.xml', 'Whiplash.xml', 'The_Gambler.xml', 'PK.xml', 'Alexander.xml', 'One_Chance.xml', 'John_Tucker_Must_Die.xml', 'Ironclad.xml', 'Trainspotting.xml', 'Heaven_Knows_What.xml', 'Charlie_and_the_Chocolate_Factory.xml', 'Contact.xml', 'Million_Dollar_Arm.xml', 'Zombieland.xml', 'Rocky_Balboa.xml', 'Dumb_and_Dumber_To.xml', 'Groundhog_Day.xml', 'Stardust.xml', 'Life_of_Crime.xml', 'New_Kids_Nitro.xml', 'The_Golden_Era.xml', 'Moonrise_Kingdom.xml', 'The_Lego_Movie.xml', \"The_King's_Speech.xml\", 'I_Am_Big_Bird__The_Caroll_Spinney_Story.xml', 'Avatar.xml', 'Dracula_Untold.xml', 'Neighbors.xml', 'Mardaani.xml', 'Interview_with_the_Vampire__The_Vampire_Chronicles.xml', 'The_Equalizer.xml', 'Pirates_of_the_Caribbean__The_Curse_of_the_Black_Pearl.xml', 'Guardians_of_the_Galaxy.xml', 'The_Monuments_Men.xml', 'The_Rewrite.xml', 'What_We_Do_in_the_Shadows.xml', 'Fury.xml', 'Divergent.xml', 'Belle_de_Jour.xml', 'Hector_and_the_Search_for_Happiness.xml', 'Sleepy_Hollow.xml', 'Hungry_Hearts.xml', 'X-Men__Days_of_Future_Past.xml', '10.000_Km.xml', 'Hercules.xml', 'The_Avengers.xml', '21_Jump_Street.xml', 'Se7en.xml', 'Serena.xml', 'Soul_Surfer.xml', 'Dumbo.xml', 'Flying_Home.xml', 'Wassup_Rockers.xml', 'The_Departed.xml', 'Gone_Girl.xml', 'Watchmen.xml', 'Burlesque.xml', 'Tammy.xml', 'Frozen.xml', 'My_Own_Private_Idaho.xml', 'Billy_Elliot.xml', 'The_Water_Diviner.xml', 'Bhoothnath.xml', 'The_Hangover.xml', 'The_White_Haired_Witch_of_Lunar_Kingdom.xml', 'Kick-Ass_2.xml', 'The_Hobbit__The_Battle_of_the_Five_Armies.xml', 'Mr.___Mrs._Smith.xml', 'Django_Unchained.xml', 'Good_Morning,_Vietnam.xml', 'La_Vie_en_Rose.xml', 'Pak_Van_Mijn_Hart.xml', 'Horrible_Bosses_2.xml', 'The_Devil_Wears_Prada.xml', 'Quantum_of_Solace.xml', 'Captain_America__The_Winter_Soldier.xml', 'The_Bridges_of_Madison_County.xml', 'Birdman__Or_(The_Unexpected_Virtue_of_Ignorance).xml', 'Who_Framed_Roger_Rabbit.xml', 'La_Camioneta__The_Journey_of_One_American_School_Bus.xml', 'American_Sniper.xml', 'From_A_to_B.xml', 'Yves_Saint_Laurent.xml', 'Finding_Fanny.xml', 'The_Voices.xml', 'Blended.xml', 'Oliver___Company.xml', 'There_Will_Be_Blood.xml', 'Love,_Rosie.xml', 'Kingsman__The_Secret_Service.xml', 'Kick-Ass.xml', 'Clash_of_the_Titans.xml', 'Trash.xml', 'Unbroken.xml', 'Dances_with_Wolves.xml', 'Mrs._Doubtfire.xml', 'Padosan.xml', 'Alexander_and_the_Terrible,_Horrible,_No_Good,_Very_Bad_Day.xml', 'How_to_Train_Your_Dragon_2.xml', 'Pride___Prejudice.xml', 'X-Men__First_Class.xml', 'The_Hundred-Foot_Journey.xml', 'Tommy_Boy.xml', 'Moonstruck.xml', 'The_Girl_Next_Door.xml', 'Magic_Mike.xml', 'In_Her_Shoes.xml', 'The_Face_Reader.xml', 'School_of_Rock.xml', 'The_Little_Mermaid.xml', 'Anastasia.xml', 'The_Fox_and_the_Hound.xml', 'Good_People.xml', 'Paddington.xml', 'Thelma___Louise.xml', 'Selma.xml', 'Wish_I_Was_Here.xml', \"A_Bug's_Life.xml\", 'Bridges_of_Sarajevo.xml', 'Gran_Torino.xml', 'Good_Will_Hunting.xml', 'The_Good,_the_Bad_and_the_Ugly.xml', 'Ratatouille.xml', 'Oorlogswinter.xml']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "import numpy as np\n",
    "\n",
    "# define the path\n",
    "currentDirectory = pathlib.Path('data/Test_Set/XML')\n",
    "\n",
    "# define the pattern\n",
    "currentPattern = \"*.xml\"\n",
    "all_xml_files = []\n",
    "for currentFile in currentDirectory.glob(currentPattern):\n",
    "    all_xml_files.append(currentFile.parts[-1])\n",
    "    \n",
    "print(all_xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_XML(xml_file, name, df_cols):\n",
    "            global out_df\n",
    "\n",
    "            xtree = et.parse(xml_file)\n",
    "            xroot = xtree.getroot()\n",
    "            fin = []\n",
    "            res = []\n",
    "            res.append(name[:-4])\n",
    "            \n",
    "            for node in xroot:\n",
    "                for i in node_cols:\n",
    "                    res.append(node.attrib.get(i))\n",
    "\n",
    "            fin.append(res)\n",
    "            print(fin)\n",
    "            out_df = pd.DataFrame(data=fin, columns =meta_cols)\n",
    "            return out_df\n",
    "        \n",
    "def parse_XML1(xml_file, name, df_cols, df):\n",
    "            global out_df\n",
    "            xtree = et.parse(xml_file)\n",
    "            xroot = xtree.getroot()\n",
    "            fin = []\n",
    "            res = []\n",
    "            res.append(name[:-4])\n",
    "            for node in xroot:\n",
    "                for i in node_cols:\n",
    "                    res.append(node.attrib.get(i))\n",
    "\n",
    "            fin.append(res)\n",
    "            df1 = pd.DataFrame(data=fin, columns =meta_cols)\n",
    "            \n",
    "            frames = [df, df1]\n",
    "            \n",
    "            out_df = pd.concat(frames)\n",
    "            \n",
    "            return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = [\"filename\",\"language\", \"year\", \"genre\", \"country\",\n",
    "            \"runtime\", \"rated\"]\n",
    "\n",
    "node_cols = [\"language\", \"year\", \"genre\", \"country\",\n",
    "            \"runtime\", \"rated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Sleeping_Beauty', 'English', '1959', 'Animation, Family, Fantasy', 'USA', '75 min', 'APPROVED']]\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "for i in all_xml_files:\n",
    "    if c==1:\n",
    "        parse_XML(\"data/Test_Set/XML/\" + i, i,  meta_cols)\n",
    "        c=43\n",
    "    else:\n",
    "        parse_XML1(\"data/Test_Set/XML/\"+i, i, meta_cols, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground = pd.read_csv(\"data/Test_Set/test_set_labels.csv\", delimiter=\";\", quoting = 3)\n",
    "# Rename columns for joining afterwards\n",
    "df_ground.columns = [\"movie\", \"filename\", \"goodforairplane\"]\n",
    "# Only for TestLabels because 2 files contain .mp4 ending\n",
    "df_ground[\"filename\"] = df_ground[\"filename\"].str.replace(\".mp4\",\"\")\n",
    "# Because 4 lines have \"\" in their names\n",
    "df_ground[\"movie\"] = df_ground[\"movie\"].str.replace('\"',\"\")\n",
    "df_ground[\"goodforairplane\"] = df_ground[\"goodforairplane\"].str.replace('\"',\"\")\n",
    "df_ground[\"goodforairplane\"] = df_ground[\"goodforairplane\"].astype(int)\n",
    "# Check for duplicates\n",
    "df_ground[df_ground.duplicated([\"filename\"])]\n",
    "# Remove duplicates\n",
    "i = df_ground[df_ground[\"movie\"] == \"10.000_km\"].index\n",
    "df_ground = df_ground.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_Fish_Called_Wanda\n"
     ]
    }
   ],
   "source": [
    "a = df_ground[\"filename\"].sort_values()\n",
    "b = out_df[\"filename\"].sort_values()\n",
    "\n",
    "for i in a.values:\n",
    "    if i in b.values:\n",
    "        continue\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.merge(df_ground, out_df, on=\"filename\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_join.drop([\"movie\", \"filename\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "count=0\n",
    "for i in df_join[\"genre\"].values:\n",
    "    df_join[\"genre\"].values[count] = i.replace(\" \", \"\")\n",
    "    count+=1\n",
    "    \n",
    "count=0\n",
    "for i in df_join[\"language\"].values:\n",
    "    df_join[\"language\"].values[count] = i.replace(\" \", \"\")\n",
    "    count+=1\n",
    "    \n",
    "    \n",
    "count=0\n",
    "for i in df_join[\"country\"].values:\n",
    "    df_join[\"country\"].values[count] = i.replace(\" \", \"\")\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = df_join.genre.str.split(\",\", expand=True).stack()\n",
    "language = df_join.language.str.split(\",\", expand=True).stack()\n",
    "country = df_join.country.str.split(\",\", expand=True).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.concat([df_join, \n",
    "                pd.get_dummies(genre, prefix=\"g\").groupby(level=0).sum()],axis=1) \\\n",
    "                .drop([\"genre\"],axis=1)\n",
    "\n",
    "df_join = pd.concat([df_join, \n",
    "                pd.get_dummies(language, prefix=\"l\").groupby(level=0).sum()],axis=1) \\\n",
    "                .drop([\"language\"],axis=1)\n",
    "\n",
    "df_join = pd.concat([df_join, \n",
    "                pd.get_dummies(country, prefix=\"c\").groupby(level=0).sum()],axis=1) \\\n",
    "                .drop([\"country\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.columns\n",
    "df_join[\"runtime\"] = df_join[\"runtime\"].apply(lambda x: x.split(\" min\")[0])\n",
    "df_join[\"runtime\"] = df_join[\"runtime\"].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.to_csv(\"metadata_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "goodforairplanes        0\n",
       "year                    0\n",
       "runtime                 2\n",
       "rated                   0\n",
       "g_Action                0\n",
       "                       ..\n",
       "c_Turkey                0\n",
       "c_UK                    0\n",
       "c_USA                   0\n",
       "c_UnitedArabEmirates    0\n",
       "c_WestGermany           0\n",
       "Length: 101, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
